{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "from latincyreaders import TesseraeReader, AnnotationLevel\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up reader\n",
    "\n",
    "T = TesseraeReader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fileids and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ammianus.rerum_gestarum.part.14.tess',\n",
      " 'ammianus.rerum_gestarum.part.15.tess',\n",
      " 'ammianus.rerum_gestarum.part.16.tess',\n",
      " 'ammianus.rerum_gestarum.part.17.tess',\n",
      " 'ammianus.rerum_gestarum.part.18.tess',\n",
      " 'ammianus.rerum_gestarum.part.19.tess',\n",
      " 'ammianus.rerum_gestarum.part.20.tess',\n",
      " 'ammianus.rerum_gestarum.part.21.tess',\n",
      " 'ammianus.rerum_gestarum.part.22.tess',\n",
      " 'ammianus.rerum_gestarum.part.23.tess']\n"
     ]
    }
   ],
   "source": [
    "## First 10 filenames\n",
    "\n",
    "files = T.fileids()[:10]\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horace.ars_poetica.tess',\n",
      " 'horace.carmen_saeculare.tess',\n",
      " 'horace.epistles.tess',\n",
      " 'horace.epodes.tess',\n",
      " 'horace.odes.part.1.tess',\n",
      " 'horace.odes.part.2.tess',\n",
      " 'horace.odes.part.3.tess',\n",
      " 'horace.odes.part.4.tess',\n",
      " 'horace.satires.part.1.tess',\n",
      " 'horace.satires.part.2.tess']\n"
     ]
    }
   ],
   "source": [
    "# Get files by pattern match (regex)\n",
    "files = T.fileids(match='horace')\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vergil.aeneid.part.1.tess',\n",
      " 'vergil.aeneid.part.2.tess',\n",
      " 'vergil.aeneid.part.3.tess',\n",
      " 'vergil.aeneid.part.4.tess',\n",
      " 'vergil.aeneid.part.5.tess',\n",
      " 'vergil.aeneid.part.6.tess',\n",
      " 'vergil.aeneid.part.7.tess',\n",
      " 'vergil.aeneid.part.8.tess',\n",
      " 'vergil.aeneid.part.9.tess',\n",
      " 'vergil.aeneid.part.10.tess',\n",
      " 'vergil.aeneid.part.11.tess',\n",
      " 'vergil.aeneid.part.12.tess']\n"
     ]
    }
   ],
   "source": [
    "# Get files by pattern - supports regex\n",
    "files = T.fileids(match=r'vergil.*aeneid')\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cicero.academica.tess',\n",
      " 'cicero.brutus.tess',\n",
      " 'cicero.cum_populo_gratias_egit.tess',\n",
      " 'cicero.de_amicitia.tess',\n",
      " 'cicero.de_divinatione.tess',\n",
      " 'cicero.de_domo_sua.tess',\n",
      " 'cicero.de_fato.tess',\n",
      " 'cicero.de_finibus_bonorum_et_malorum.part.1.tess',\n",
      " 'cicero.de_finibus_bonorum_et_malorum.part.2.tess',\n",
      " 'cicero.de_finibus_bonorum_et_malorum.part.3.tess']\n"
     ]
    }
   ],
   "source": [
    "# Get files by partial match\n",
    "files = T.fileids(match='cicero')[:10]\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ovid.amores.part.1.tess',\n",
      " 'ovid.amores.part.2.tess',\n",
      " 'ovid.amores.part.3.tess',\n",
      " 'ovid.ars_amatoria.part.1.tess',\n",
      " 'ovid.ars_amatoria.part.2.tess',\n",
      " 'ovid.ars_amatoria.part.3.tess',\n",
      " 'ovid.ex_ponto.part.1.tess',\n",
      " 'ovid.ex_ponto.part.2.tess',\n",
      " 'ovid.ex_ponto.part.3.tess',\n",
      " 'ovid.ex_ponto.part.4.tess',\n",
      " 'ovid.fasti.part.1.tess',\n",
      " 'ovid.fasti.part.2.tess',\n",
      " 'ovid.fasti.part.3.tess',\n",
      " 'ovid.fasti.part.4.tess',\n",
      " 'ovid.fasti.part.5.tess',\n",
      " 'ovid.fasti.part.6.tess',\n",
      " 'ovid.heroides.part.1.1-15.tess',\n",
      " 'ovid.heroides.part.2.16-21.tess',\n",
      " 'ovid.ibis.tess',\n",
      " 'ovid.medicamina_faciei_femineae.tess',\n",
      " 'ovid.metamorphoses.part.1.tess',\n",
      " 'ovid.metamorphoses.part.2.tess',\n",
      " 'ovid.metamorphoses.part.3.tess',\n",
      " 'ovid.metamorphoses.part.4.tess',\n",
      " 'ovid.metamorphoses.part.5.tess',\n",
      " 'ovid.metamorphoses.part.6.tess',\n",
      " 'ovid.metamorphoses.part.7.tess',\n",
      " 'ovid.metamorphoses.part.8.tess',\n",
      " 'ovid.metamorphoses.part.9.tess',\n",
      " 'ovid.metamorphoses.part.10.tess',\n",
      " 'ovid.metamorphoses.part.11.tess',\n",
      " 'ovid.metamorphoses.part.12.tess',\n",
      " 'ovid.metamorphoses.part.13.tess',\n",
      " 'ovid.metamorphoses.part.14.tess',\n",
      " 'ovid.metamorphoses.part.15.tess',\n",
      " 'ovid.remedia_amoris.tess',\n",
      " 'ovid.tristia.part.1.tess',\n",
      " 'ovid.tristia.part.2.tess',\n",
      " 'ovid.tristia.part.3.tess',\n",
      " 'ovid.tristia.part.4.tess',\n",
      " 'ovid.tristia.part.5.tess',\n",
      " 'seneca.de_providentia.tess']\n"
     ]
    }
   ],
   "source": [
    "# Case-insensitive regex matching\n",
    "files = T.fileids(match=r'ovid')\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lucretius.de_rerum_natura.part.1.tess',\n",
      " 'lucretius.de_rerum_natura.part.2.tess',\n",
      " 'lucretius.de_rerum_natura.part.3.tess',\n",
      " 'lucretius.de_rerum_natura.part.4.tess',\n",
      " 'lucretius.de_rerum_natura.part.5.tess',\n",
      " 'lucretius.de_rerum_natura.part.6.tess',\n",
      " 'polignac.antilucretius.tess']\n"
     ]
    }
   ],
   "source": [
    "# Multiple pattern examples\n",
    "files = T.fileids(match='lucretius')\n",
    "pprint(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 900\n"
     ]
    }
   ],
   "source": [
    "# Get all files\n",
    "all_files = T.fileids()\n",
    "print(f\"Total files: {len(all_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by metadata\n",
    "\n",
    "The `match` parameter uses regex, which can be too broad. For precise filtering, use metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: regex match can be too broad\n",
    "# Searching for \"lucretius\" also finds \"antilucretius\"\n",
    "\n",
    "files = T.fileids(match='lucretius')\n",
    "pprint(files)\n",
    "# Note: polignac.antilucretius is included!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: filter by exact author using metadata\n",
    "# This gets ONLY Lucretius, not Anti-Lucretius\n",
    "\n",
    "lucretius_files = [\n",
    "    fileid for fileid, meta in T.metadata()\n",
    "    if meta.get('author') == 'Lucretius'\n",
    "]\n",
    "pprint(lucretius_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by genre (e.g., find all epic poetry)\n",
    "\n",
    "epic_files = [\n",
    "    fileid for fileid, meta in T.metadata()\n",
    "    if meta.get('genre') == 'epic'\n",
    "]\n",
    "print(f\"Epic texts: {len(epic_files)} files\")\n",
    "pprint(epic_files[:10])  # First 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by date: texts before 50 BCE (negative dates = BCE)\n",
    "\n",
    "def get_date(meta):\n",
    "    \"\"\"Parse date string to int, handling missing/invalid values.\"\"\"\n",
    "    try:\n",
    "        return int(meta.get('date', 0))\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "# Texts from before 50 BCE\n",
    "early_republic = [\n",
    "    fileid for fileid, meta in T.metadata()\n",
    "    if (d := get_date(meta)) is not None and d < -50\n",
    "]\n",
    "print(f\"Texts before 50 BCE: {len(early_republic)} files\")\n",
    "pprint(early_republic[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augustan era texts (roughly 43 BCE - 14 CE)\n",
    "\n",
    "augustan = [\n",
    "    fileid for fileid, meta in T.metadata()\n",
    "    if (d := get_date(meta)) is not None and -43 <= d <= 14\n",
    "]\n",
    "print(f\"Augustan era texts: {len(augustan)} files\")\n",
    "pprint(augustan[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all available genres in the corpus\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "genres = Counter(\n",
    "    meta.get('genre') for _, meta in T.metadata()\n",
    "    if meta.get('genre')\n",
    ")\n",
    "print(\"Available genres:\")\n",
    "for genre, count in genres.most_common():\n",
    "    print(f\"  {genre}: {count} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine filters: lyric poetry from the Augustan era\n",
    "\n",
    "augustan_lyric = [\n",
    "    fileid for fileid, meta in T.metadata()\n",
    "    if meta.get('genre') == 'lyric'\n",
    "    and (d := get_date(meta)) is not None \n",
    "    and -43 <= d <= 14\n",
    "]\n",
    "print(f\"Augustan lyric poetry: {len(augustan_lyric)} files\")\n",
    "pprint(augustan_lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata can be accessed without NLP processing (instant)\n",
    "# Use get_metadata() to avoid loading the spaCy model\n",
    "\n",
    "catullus = 'catullus.carmina.tess'\n",
    "\n",
    "# Fast: get metadata directly (no NLP overhead)\n",
    "meta = T.get_metadata(catullus)\n",
    "\n",
    "print(f\"Metadata for {catullus}:\")\n",
    "pprint(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a file to work with\n",
    "catullus = 'catullus.carmina.tess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cui dono lepidum novum libellum arido modo pumice expolitum? Corneli, tibi; namque tu solebas meas esse aliquid putare nugas, iam tum cum ausus es unus Italorum omne aevum tribus explicare chartis, doctis, Iuppiter, et laboriosis! quare habe tibi quidquid hoc libelli qualecumque, quod, o patrona virgo, plus uno maneat perenne saeclo. Passer, deliciae meae puellae, quicum ludere, quem in sinu tenere, cui primum digitum dare adpetenti et acris solet incitare morsus, cum desiderio meo nitenti carum nescio quid libet iocari (et solaciolum sui doloris, credo, ut tum gravis adquiescat ardor), tecum ludere sicut ipsa possem et tristis animi levare curas! Tam gratum est mihi quam ferunt puellae pernici aureolum fuisse malum, quod zonam solvit diu ligatam. Lugete, o Veneres Cupidinesque et quantum est hominum venustiorum! passer mortuus est meae puellae, passer, deliciae meae puellae, quem plus illa oculis suis amabat; nam mellitus erat, suamque norat ipsa tam bene quam puella matrem, nec sese a gremio illius movebat, sed circumsiliens modo huc modo illuc ad solam dominam usque pipiabat. qui nunc it per iter tenebricosum illuc unde negant redire quemquam. at vobis male sit, malae tenebrae Orci, quae omnia bella devoratis; tam bellum mihi passerem abstulistis. o factum male! o miselle passer! tua nunc opera meae puellae flendo turgiduli rubent ocelli. Phasellus ille, quem videtis, hospites, ait fuisse navium celerrimus, neque ullius natantis impetum trabis nequisse praeterire, sive palmulis opus foret volare sive linteo. et hoc negat minacis Hadriatici negare litus insulasve Cycladas Rhodumque nobilem horridamque Thraciam Propontida trucemve Ponticum sinum, ubi iste post phasellus antea fuit comata silva: nam Cytorio in iugo loquente saepe sibilum edidit coma. Amastri Pontica et Cytore buxifer, tibi haec fuisse et esse cognitissima ait phasellus; ultima ex origine tuo stetisse dicit in cacumine, tuo imbuisse palmulas in aequore, et inde tot per impotentia freta erum tulisse, laeva sive dextera vocaret aura, sive utrumque Iuppiter simul secundus incidisset in pedem; neque ulla vota litoralibus diis sibi esse facta, cum veniret a mari novissimo hunc ad usque limpidum lacum. sed haec prius fuere: nunc recondita senet quiete seque dedicat tibi, gemelle Castor et gemelle Castoris. Vivamus, mea Lesbia, atque amemus, rumoresque senum severiorum omnes unius aestimemus assis. soles occidere et redire possunt: nobis, cum semel occidit brevis lux, nox est perpetua una dormienda. da mi basia mille, deinde centum, dein mille altera, dein secunda centum, deinde usque altera mille, deinde centum, dein, cum milia multa fecerimus, conturbabimus illa, ne sciamus, aut ne quis malus invidere possit, cum tantum\n"
     ]
    }
   ],
   "source": [
    "## Docs - spaCy Doc objects with NLP annotations\n",
    "\n",
    "catullus_doc = next(T.docs(catullus))\n",
    "print(catullus_doc[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cui dono lepidum novum libellum arido modo pumice expolitum? Corneli, tibi; '\n",
      " 'namque tu solebas meas esse aliquid putare nugas, iam tum cum ausus es unus '\n",
      " 'Italorum omne aevum tribus explicare chartis, doctis, Iuppiter, et '\n",
      " 'laboriosis! quare habe tibi quidquid hoc libelli qualecumque, quod, o '\n",
      " 'patrona virgo, plus uno maneat perenne saeclo. Passer, deliciae meae '\n",
      " 'puellae, quicum ludere, quem in sinu tener')\n"
     ]
    }
   ],
   "source": [
    "## Texts - raw strings (zero NLP overhead)\n",
    "\n",
    "catullus_text = next(T.texts(catullus))\n",
    "pprint(catullus_text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 citation -> span mappings:\n",
      "  <cat. 1.1>: Cui dono lepidum novum libellum...\n",
      "  <cat. 1.2>: arido modo pumice expolitum?...\n",
      "  <cat. 1.3>: Corneli, tibi; namque tu solebas...\n",
      "  <cat. 1.4>: meas esse aliquid putare nugas,...\n",
      "  <cat. 1.5>: iam tum cum ausus es unus Italorum...\n",
      "  <cat. 1.6>: omne aevum tribus explicare chartis,...\n",
      "  <cat. 1.7>: doctis, Iuppiter, et laboriosis!...\n",
      "  <cat. 1.8>: quare habe tibi quidquid hoc libelli...\n",
      "  <cat. 1.9>: qualecumque, quod, o patrona virgo,...\n",
      "  <cat. 1.10>: plus uno maneat perenne saeclo....\n"
     ]
    }
   ],
   "source": [
    "## Doc Rows - citation -> text mapping\n",
    "\n",
    "catullus_docrows = next(T.doc_rows(catullus))\n",
    "\n",
    "print('First 10 citation -> span mappings:')\n",
    "for i, (citation, span) in enumerate(catullus_docrows.items()):\n",
    "    if i >= 10:\n",
    "        break\n",
    "    print(f\"  {citation}: {span.text[:40]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another file for examples\n",
    "catilinam = 'cicero.in_catilinam.tess'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paras (not implemented - Tesserae format doesn't have paragraphs)\n",
    "# Use sents() or lines() instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent 1: quo usque tandem abutere, Catilina, patientia nostra?\n",
      "Sent 2: quam diu etiam furor iste tuus nos eludet?\n",
      "Sent 3: quem ad finem sese effrenata iactabit audacia?\n",
      "Sent 4: nihilne te nocturnum praesidium Palati, nihil urbis vigiliae, nihil timor populi, nihil concursus bonorum omnium, nihil hic munitissimus habendi senatus locus, nihil horum ora voltusque moverunt?\n",
      "Sent 5: patere tua consilia non sentis, constrictam iam horum omnium scientia teneri coniurationem tuam non vides?\n"
     ]
    }
   ],
   "source": [
    "# Sents - spaCy Span objects\n",
    "\n",
    "# Segmentation and tokenization done using la_core_web_lg model\n",
    "catilinam_sents = T.sents(catilinam)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    print(f'Sent {i}: {next(catilinam_sents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 1: quo\n",
      "Word 2: usque\n",
      "Word 3: tandem\n",
      "Word 4: abutere\n",
      "Word 5: ,\n",
      "Word 6: Catilina\n",
      "Word 7: ,\n",
      "Word 8: patientia\n",
      "Word 9: nostra\n"
     ]
    }
   ],
   "source": [
    "# Tokens - spaCy Token objects\n",
    "\n",
    "catilinam_tokens = T.tokens(catilinam)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print(f'Word {i}: {next(catilinam_tokens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available attributes: ['ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type']...\n"
     ]
    }
   ],
   "source": [
    "# spaCy Token has many useful attributes\n",
    "catilinam_tokens = T.tokens(catilinam)\n",
    "token = next(catilinam_tokens)\n",
    "print(f\"Available attributes: {[a for a in dir(token) if not a.startswith('_')][:15]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token linguistic attributes (BASIC level: text, lemma, POS, tag)\n",
    "# Note: dep_ requires AnnotationLevel.FULL\n",
    "\n",
    "catilinam_tokens = T.tokens(catilinam)\n",
    "t = next(catilinam_tokens)\n",
    "print(f\"text: {t.text}, lemma: {t.lemma_}, pos: {t.pos_}, tag: {t.tag_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quo "
     ]
    }
   ],
   "source": [
    "# For custom text processing, work with the raw text or spaCy Doc\n",
    "# The preprocess parameter has been removed - use spaCy pipeline components instead\n",
    "\n",
    "# Get text as strings\n",
    "for token_text in T.tokens(catilinam, as_text=True):\n",
    "    # Apply your own processing\n",
    "    processed = token_text.lower()\n",
    "    print(processed, end=' ')\n",
    "    break  # Just show first token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tok Sent 1: [('quo', 'quo', 'adverb'), ('usque', 'usque', 'adverb'), ('tandem', 'tandem', 'adverb'), ('abutere', 'abutor', 'verb'), (',', ',', 'punc'), ('Catilina', 'Catilina', 'proper_noun'), (',', ',', 'punc'), ('patientia', 'patientia', 'noun'), ('nostra', 'noster', 'adjective'), ('?', '?', 'punc')]\n",
      "\n",
      "Tok Sent 2: [('quam', 'qui', 'conjunction'), ('diu', 'diu', 'adverb'), ('etiam', 'etiam', 'adverb'), ('furor', 'furor', 'noun'), ('iste', 'iste', 'adjective'), ('tuus', 'tuus', 'adjective'), ('nos', 'nos', 'pronoun'), ('eludet', 'eludo', 'verb'), ('?', '?', 'punc')]\n",
      "\n",
      "Tok Sent 3: [('quem', 'qui', 'pronoun'), ('ad', 'ad', 'preposition'), ('finem', 'finis', 'noun'), ('sese', 'sui', 'pronoun'), ('effrenata', 'effrenatus', 'verb'), ('iactabit', 'iacto', 'verb'), ('audacia', 'audacia', 'noun'), ('?', '?', 'punc')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenized sents - use spaCy directly\n",
    "# Get (token, lemma, tag) tuples from sentences\n",
    "\n",
    "catilinam_sents = T.sents(catilinam)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    sent = next(catilinam_sents)\n",
    "    tok_sent = [(t.text, t.lemma_, t.tag_) for t in sent]\n",
    "    print(f'Tok Sent {i}: {tok_sent}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tok Sent 1: ['quo', 'usque', 'tandem', 'abutere', ',', 'Catilina', ',', 'patientia', 'nostra', '?']\n",
      "\n",
      "Tok Sent 2: ['quam', 'diu', 'etiam', 'furor', 'iste', 'tuus', 'nos', 'eludet', '?']\n",
      "\n",
      "Tok Sent 3: ['quem', 'ad', 'finem', 'sese', 'effrenata', 'iactabit', 'audacia', '?']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenized sents, simplified (just tokens as strings)\n",
    "\n",
    "catilinam_sents = T.sents(catilinam)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    sent = next(catilinam_sents)\n",
    "    tok_sent = [t.text for t in sent]\n",
    "    print(f'Tok Sent {i}: {tok_sent}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Sent 1: quo/ADV usque/ADV tandem/ADV abutere/VERB ,/PUNCT Catilina/PROPN ,/PUNCT patientia/NOUN nostra/DET ?/PUNCT\n",
      "POS Sent 2: quam/SCONJ diu/ADV etiam/ADV furor/NOUN iste/DET tuus/DET nos/PRON eludet/VERB ?/PUNCT\n"
     ]
    }
   ],
   "source": [
    "# POS-tagged sents - token/POS pairs\n",
    "\n",
    "catilinam_sents = T.sents(catilinam)\n",
    "\n",
    "for i in range(1, 3):\n",
    "    sent = next(catilinam_sents)\n",
    "    pos_sent = [f\"{t.text}/{t.pos_}\" for t in sent]\n",
    "    print(f'POS Sent {i}: {\" \".join(pos_sent)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quo\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "# spaCy Token objects by default\n",
    "catilinam_tokens = T.tokens(catilinam)\n",
    "\n",
    "catilinam_token = next(catilinam_tokens)\n",
    "print(catilinam_token)\n",
    "print(type(next(catilinam_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quo\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Tokens as plain strings with as_text=True\n",
    "\n",
    "plaintext_tokens = T.tokens(catilinam, as_text=True)\n",
    "\n",
    "plaintext_token = next(plaintext_tokens)\n",
    "print(plaintext_token)\n",
    "print(type(plaintext_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Arma virumque cano, Troiae qui primus ab oris\n",
      "2: Italiam, fato profugus, Laviniaque venit\n",
      "3: litora, multum ille et terris iactatus et alto\n",
      "4: vi superum saevae memorem Iunonis ob iram;\n",
      "5: multa quoque et bello passus, dum conderet urbem,\n",
      "6: inferretque deos Latio, genus unde Latinum,\n",
      "7: Albanique patres, atque altae moenia Romae.\n",
      "8: Musa, mihi causas memora, quo numine laeso,\n"
     ]
    }
   ],
   "source": [
    "# Lines (citation units from the Tesserae format)\n",
    "\n",
    "aeneid = T.fileids(match='aeneid')[0]\n",
    "\n",
    "aeneid_lines = T.lines(aeneid)\n",
    "\n",
    "for i in range(1, 9):\n",
    "    print(f'{i}: {next(aeneid_lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<verg. aen. 1.1>: Arma virumque cano, Troiae qui primus ab oris\n",
      "<verg. aen. 1.2>: Italiam, fato profugus, Laviniaque venit\n",
      "<verg. aen. 1.3>: litora, multum ille et terris iactatus et alto\n",
      "<verg. aen. 1.4>: vi superum saevae memorem Iunonis ob iram;\n",
      "<verg. aen. 1.5>: multa quoque et bello passus, dum conderet urbem,\n",
      "<verg. aen. 1.6>: inferretque deos Latio, genus unde Latinum,\n",
      "<verg. aen. 1.7>: Albanique patres, atque altae moenia Romae.\n",
      "<verg. aen. 1.8>: Musa, mihi causas memora, quo numine laeso,\n"
     ]
    }
   ],
   "source": [
    "# Lines with citation information preserved\n",
    "\n",
    "aeneid_lines = T.lines(aeneid)\n",
    "\n",
    "for i in range(1, 9):\n",
    "    line = next(aeneid_lines)\n",
    "    print(f'{line._.citation}: {line}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences with citation information\n",
    "# Sentences can span multiple citation lines\n",
    "\n",
    "aeneid_doc = next(T.docs(aeneid))\n",
    "\n",
    "# Show first few sentences with their citation ranges\n",
    "for i, sent in enumerate(aeneid_doc.sents):\n",
    "    if i >= 3:\n",
    "        break\n",
    "    overlapping = [\n",
    "        span._.citation for span in aeneid_doc.spans.get(\"lines\", [])\n",
    "        if sent.start < span.end and sent.end > span.start\n",
    "    ]\n",
    "    if overlapping:\n",
    "        cit_range = f\"{overlapping[0]}–{overlapping[-1]}\" if len(overlapping) > 1 else overlapping[0]\n",
    "    else:\n",
    "        cit_range = \"?\"\n",
    "    print(f\"{cit_range}\")\n",
    "    print(f\"  {sent.text[:80]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line citation: <verg. aen. 1.1>\n",
      "Tokens in line: ['Arma', 'virum', 'que', 'cano', ',', 'Troiae', 'qui', 'primus', 'ab', 'oris']\n"
     ]
    }
   ],
   "source": [
    "# Tokens within citation lines\n",
    "# Access citation via the line spans\n",
    "\n",
    "aeneid_doc = next(T.docs(aeneid))\n",
    "line = aeneid_doc.spans[\"lines\"][0]\n",
    "\n",
    "print(f\"Line citation: {line._.citation}\")\n",
    "print(f\"Tokens in line: {[t.text for t in line]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ovid.metamorphoses.part.1.tess',\n",
      " 'ovid.metamorphoses.part.2.tess',\n",
      " 'ovid.metamorphoses.part.3.tess',\n",
      " 'ovid.metamorphoses.part.4.tess',\n",
      " 'ovid.metamorphoses.part.5.tess',\n",
      " 'ovid.metamorphoses.part.6.tess',\n",
      " 'ovid.metamorphoses.part.7.tess',\n",
      " 'ovid.metamorphoses.part.8.tess',\n",
      " 'ovid.metamorphoses.part.9.tess',\n",
      " 'ovid.metamorphoses.part.10.tess',\n",
      " 'ovid.metamorphoses.part.11.tess',\n",
      " 'ovid.metamorphoses.part.12.tess',\n",
      " 'ovid.metamorphoses.part.13.tess',\n",
      " 'ovid.metamorphoses.part.14.tess',\n",
      " 'ovid.metamorphoses.part.15.tess']\n"
     ]
    }
   ],
   "source": [
    "# Get files by pattern\n",
    "metamorphoses = T.fileids(match='ovid.metamorphoses')\n",
    "pprint(metamorphoses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: In nova fert animus mutatas dicere formas corpora; di, coeptis (nam vos mutastis et illas) adspirate\n",
      "Normalized: in noua fert animus mutatas dicere formas corpora di coeptis nam uos mutastis et illas adspirate\n"
     ]
    }
   ],
   "source": [
    "# Custom text normalization example\n",
    "# Use this pattern when you need specific preprocessing\n",
    "\n",
    "def normalize_latin(text):\n",
    "    \"\"\"Normalize Latin text for analysis.\"\"\"\n",
    "    text = text.lower()\n",
    "    # Normalize u/v and i/j\n",
    "    text = text.replace('v', 'u').replace('j', 'i')\n",
    "    # Remove punctuation  \n",
    "    import string\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return \" \".join(text.split()).strip()\n",
    "\n",
    "# Example usage on raw text\n",
    "sample = next(T.texts(metamorphoses[0]))[:100]\n",
    "print(f\"Original: {sample}\")\n",
    "print(f\"Normalized: {normalize_latin(sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Concordance\n\n# Build a concordance: word -> list of citations where it appears\n# Group by lemma (default) to see all forms of a word together\n\ncatullus_conc = T.concordance(fileids=catullus, basis=\"lemma\")\n\nprint(f\"Unique lemmas in Catullus: {len(catullus_conc)}\")\nprint()\n\n# Look up a specific lemma\nif \"amor\" in catullus_conc:\n    print(\"Citations for 'amor':\")\n    for cit in catullus_conc[\"amor\"][:10]:\n        print(f\"  {cit}\")\n    if len(catullus_conc[\"amor\"]) > 10:\n        print(f\"  ... and {len(catullus_conc['amor']) - 10} more\")"
  },
  {
   "cell_type": "code",
   "source": "# Concordance by surface text form (exact spelling)\ncatullus_conc_text = T.concordance(fileids=catullus, basis=\"text\")\n\n# Different forms of 'puella' (girl)\npuella_forms = [\"puella\", \"puellae\", \"puellam\", \"puellas\", \"puellis\"]\nprint(\"Occurrences of 'puella' forms in Catullus:\")\nfor form in puella_forms:\n    if form in catullus_conc_text:\n        count = len(catullus_conc_text[form])\n        print(f\"  {form}: {count} occurrences\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## KWIC (Keyword in Context)\n\nFind words with surrounding context - useful for studying word usage patterns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Basic KWIC search - find \"amor\" with 5 tokens of context on each side\nfor hit in T.kwic(\"amor\", fileids=catullus, window=5, limit=5):\n    print(f\"{hit['left']} [{hit['match']}] {hit['right']}\")\n    print(f\"  -- {hit['citation']}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# KWIC by lemma - finds all forms of a word (e.g., amo, amat, amant, amavit)\n# Use by_lemma=True to match against lemmatized forms\n\nfor hit in T.kwic(\"amo\", fileids=catullus, by_lemma=True, window=4, limit=5):\n    print(f\"{hit['left']} [{hit['match']}] {hit['right']}\")\n    print(f\"  -- {hit['citation']}\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 900\n",
      "\n",
      "Sample file: ammianus.rerum_gestarum.part.14.tess\n",
      "Character count: 63253\n",
      "Word count (approx): 8201\n"
     ]
    }
   ],
   "source": [
    "## Basic descriptive stats\n",
    "# Count files, estimate tokens, etc.\n",
    "\n",
    "# Quick corpus overview\n",
    "files = T.fileids()\n",
    "print(f\"Total files: {len(files)}\")\n",
    "\n",
    "# Sample stats from one file\n",
    "sample_file = files[0]\n",
    "sample_text = next(T.texts(sample_file))\n",
    "print(f\"\\nSample file: {sample_file}\")\n",
    "print(f\"Character count: {len(sample_text)}\")\n",
    "print(f\"Word count (approx): {len(sample_text.split())}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output for full corpus\n",
    "\n",
    "A full describe() method will be added in a future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for catullus.carmina.tess:\n",
      "  Sentences: 913\n",
      "  Tokens: 15536\n",
      "  Citation lines: 2285\n"
     ]
    }
   ],
   "source": [
    "## Stats for a specific file\n",
    "\n",
    "catullus_doc = next(T.docs(catullus))\n",
    "\n",
    "print(f'Stats for {catullus}:')\n",
    "print(f'  Sentences: {len(list(catullus_doc.sents))}')\n",
    "print(f'  Tokens: {len(catullus_doc)}')\n",
    "print(f'  Citation lines: {len(catullus_doc.spans.get(\"lines\", []))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features in latincyreaders\n",
    "\n",
    "The following sections demonstrate new search and filtering capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ammianus.rerum_gestarum.part.14.tess <amm. 14.11.15>: found ['Thebaeas']\n",
      "  → Emensis itaque longis intervallis et planis, cum Hadrianopol...\n",
      "\n",
      "ammianus.rerum_gestarum.part.15.tess <amm. 15.10.9>: found ['Thebaeus']\n",
      "  → Et primam Thebaeus Hercules, ad Geryonem exstinguendum (ut r...\n",
      "\n",
      "ammianus.rerum_gestarum.part.17.tess <amm. 17.4.2>: found ['Thebas', 'Thebais']\n",
      "  → Urbem priscis saeculis conditam, ambitiosa moenium strue et ...\n",
      "\n",
      "ammianus.rerum_gestarum.part.19.tess <amm. 19.12.3>: found ['Thebaidis']\n",
      "  → Materiam autem in infinitum quaestionibus extendendis dedit ...\n",
      "\n",
      "ammianus.rerum_gestarum.part.22.tess <amm. 22.16.1>: found ['Thebaida']\n",
      "  → Tres provincias Aegyptus fertur habuisse temporibus priscis,...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# search() - fast regex search across the corpus (no NLP required)\n",
    "from itertools import islice\n",
    "\n",
    "# Find lines mentioning Thebes (limit to first 5 results)\n",
    "results = T.search(r'\\bTheb\\w+\\b')\n",
    "for fileid, citation, text, matches in islice(results, 5):\n",
    "    print(f\"{fileid} {citation}: found {matches}\")\n",
    "    print(f\"  → {text[:60]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<amm. 17.4.2>: Urbem priscis saeculis conditam, ambitiosa moenium strue et portarum c...\n",
      "<amm. 22.16.2>: Igitur Thebais multas inter urbes clariores aliis Hermopolim habet, et...\n",
      "<apul.fl. 22>: Crates ille Diogenis sectator, qui ut lar familiaris apud homines aeta...\n",
      "<apul.met. 4.9>: Suscipit unus ex illo posteriore numero: Tune solus ignoras longe faci...\n",
      "<aus. epit. 27.1>: THEBARUM regina fui, Sipyleia cautes...\n"
     ]
    }
   ],
   "source": [
    "# find_lines() - find citation lines containing specific words/patterns\n",
    "\n",
    "# Find lines with specific word forms\n",
    "forms = [\"Thebas\", \"Thebarum\", \"Thebis\"]\n",
    "for fileid, citation, text in islice(T.find_lines(forms=forms), 5):\n",
    "    print(f\"{citation}: {text[:70]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<amm. 14.1.0>: Galli Caesaris saevitia....\n",
      "  Matched: ['Caesaris']\n",
      "\n",
      "<amm. 14.1.1>: Post emensos insuperabilis expeditionis eventus, languentibus partium animis, qu...\n",
      "  Matched: ['Caesaris']\n",
      "\n",
      "<amm. 14.1.5>: sed quidquid Caesaris implacabilitati sedisset, id velut fas iusque perpensum, c...\n",
      "  Matched: ['Caesaris']\n",
      "\n",
      "<amm. 14.1.6>: Hi peragranter et dissimulanter honoratorum circulis assistendo, pervadendoque d...\n",
      "  Matched: ['Caesaris']\n",
      "\n",
      "<amm. 14.1.10>: Quibus mox Caesar acrius efferatus, velut contumaciae quoddam vexillum altius er...\n",
      "  Matched: ['Caesar']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find_sents() - find sentences containing specific words\n",
    "# Fast path: search by exact forms (uses regex, minimal NLP)\n",
    "\n",
    "for hit in islice(T.find_sents(forms=[\"Caesar\", \"Caesarem\", \"Caesaris\"]), 5):\n",
    "    print(f\"{hit['citation']}: {hit['sentence'][:80]}...\")\n",
    "    print(f\"  Matched: {hit['matches']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<amm. 14.2.1>: Namque et Isauri, quibus est usitatum saepe pacari, saepeque inopinis excursibus...\n",
      "  Matched forms: ['bella']\n",
      "\n",
      "<amm. 14.3.1>: Eo adducta re per Isauriam, rege Persarum bellis finitimis illigato, repellenteq...\n",
      "  Matched forms: ['bellis']\n",
      "\n",
      "<amm. 14.6.4>: Eius populus ab incunabulis primis ad usque pueritiae tempus extremum, quod anni...\n",
      "  Matched forms: ['bella']\n",
      "\n",
      "<amm. 14.6.4>: deinde aetatem ingressus adultam, post multiplices bellorum aerumnas, Alpes tran...\n",
      "  Matched forms: ['bellorum']\n",
      "\n",
      "<amm. 14.6.10>: Alii nullo quaerente, vultus severitate assimulata, patrimonia sua in immensum e...\n",
      "  Matched forms: ['bella']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find_sents() by lemma - slower but finds ALL forms\n",
    "# Uses NLP to lemmatize, so it catches forms you might miss\n",
    "\n",
    "# Find all sentences with any form of \"bellum\" (war)\n",
    "for hit in islice(T.find_sents(lemma=\"bellum\"), 5):\n",
    "    print(f\"{hit['citation']}: {hit['sentence'][:80]}...\")\n",
    "    print(f\"  Matched forms: {hit['matches']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cat. 1.1>: Cui dono lepidum novum libellum arido modo pumice expolitum?...\n",
      "  Matched: ['novum libellum']\n",
      "\n",
      "<cat. 1.8>: quare habe tibi quidquid hoc libelli qualecumque, quod, o patrona virgo, plus un...\n",
      "  Matched: ['perenne saeclo']\n",
      "\n",
      "<cat. 2.1>: Passer, deliciae meae puellae, quicum ludere, quem in sinu tenere, cui primum di...\n",
      "  Matched: ['primum digitum', 'tristis animi']\n",
      "\n",
      "<cat. 3.13>: at vobis male sit, malae tenebrae Orci, quae omnia bella devoratis;...\n",
      "  Matched: ['malae tenebrae']\n",
      "\n",
      "<cat. 3.16>: o miselle passer!...\n",
      "  Matched: ['miselle passer']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find_sents() with spaCy Matcher patterns - advanced pattern matching\n",
    "# Search for ADJ + NOUN sequences (e.g., \"magna voce\", \"pulchra puella\")\n",
    "\n",
    "pattern = [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}]\n",
    "for hit in islice(T.find_sents(matcher_pattern=pattern, fileids=T.fileids(match=\"catullus\")), 5):\n",
    "    print(f\"{hit['citation']}: {hit['sentence'][:80]}...\")\n",
    "    print(f\"  Matched: {hit['matches']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<amm. 14.2.8>: ['magna parte']\n",
      "<amm. 15.5.30>: ['magna industria']\n",
      "<amm. 15.5.34>: ['magnis vocibus']\n",
      "<amm. 15.7.10>: ['magna difficultate']\n",
      "<amm. 15.8.18>: ['magnis viribus']\n"
     ]
    }
   ],
   "source": [
    "# More complex Matcher patterns\n",
    "# Find sentences with a specific lemma followed by a noun\n",
    "\n",
    "pattern = [{\"LEMMA\": \"magnus\"}, {\"POS\": \"NOUN\"}]\n",
    "for hit in islice(T.find_sents(matcher_pattern=pattern), 5):\n",
    "    print(f\"{hit['citation']}: {hit['matches']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Levels\n",
    "\n",
    "Control NLP processing overhead with `AnnotationLevel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available annotation levels:\n",
      "  NONE: none\n",
      "  TOKENIZE: tokenize\n",
      "  BASIC: basic\n",
      "  FULL: full\n"
     ]
    }
   ],
   "source": [
    "# AnnotationLevel controls how much NLP processing to apply\n",
    "\n",
    "# NONE - use texts() for raw strings (fastest)\n",
    "# TOKENIZE - tokenization + sentence boundaries only\n",
    "# BASIC - adds lemmatization and POS tagging (default)\n",
    "# FULL - full pipeline including NER and dependency parsing\n",
    "\n",
    "# Create readers with different annotation levels\n",
    "reader_fast = TesseraeReader(annotation_level=AnnotationLevel.TOKENIZE)\n",
    "reader_full = TesseraeReader(annotation_level=AnnotationLevel.FULL)\n",
    "\n",
    "print(\"Available annotation levels:\")\n",
    "for level in AnnotationLevel:\n",
    "    print(f\"  {level.name}: {level.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSV export (first 500 chars):\n",
      "fileid\tcitation\tmatches\tsentence\n",
      "catullus.carmina.tess\t<cat. 11.21>\tamorem\tnec meum respectet, ut ante, amorem, qui illius culpa cecidit velut prati ultimi flos, praetereunte postquam tactus aratro est.\n",
      "catullus.carmina.tess\t<cat. 30.6>\tamorem\tcerte tute iubebas animam tradere, inique, me inducens in amorem, quasi tuta omnia mi forent.\n",
      "catullus.carmina.tess\t<cat. 45.7>\tAmor\t” hoc ut dixit, Amor, sinistra ut ante, dextra sternuit adprobationem.\n",
      "catullus.carmina.tess\t<cat. 55.17>\tamoris\tsi linguam\n"
     ]
    }
   ],
   "source": [
    "# Export search results to TSV, CSV, or JSONL\n",
    "\n",
    "results = T.find_sents(forms=[\"amor\", \"amoris\", \"amorem\"], fileids=T.fileids(match=\"catullus\"))\n",
    "export = T.export_search_results(results, format=\"tsv\")\n",
    "\n",
    "print(\"TSV export (first 500 chars):\")\n",
    "print(export[:500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}