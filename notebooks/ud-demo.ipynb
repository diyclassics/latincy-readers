{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# UDReader Demo\n",
        "\n",
        "This notebook demonstrates the `UDReader` for working with Universal Dependencies format files.\n",
        "\n",
        "**Supported formats:**\n",
        "- `.conllu` - Full CoNLL-U format with dependency annotations\n",
        "- `.conllup` - LASLA variant without dependency columns (HEAD, DEPREL)\n",
        "\n",
        "**Key features:**\n",
        "- Annotations come directly from the file by default (not LatinCy)\n",
        "- Access UD-specific fields via `Token._.ud_*` extensions\n",
        "- Detect format type with `has_dependencies()`\n",
        "- Raw token data access with `tokens_with_annotations()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-0",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Imports\n",
        "\n",
        "from latincyreaders import UDReader, AnnotationLevel\n",
        "\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Set up reader\n",
        "\n",
        "# Point to your CONLLU/CONLLUP corpus directory\n",
        "# Example: UD Latin treebanks, LASLA corpus, etc.\n",
        "\n",
        "UD_PATH = \"/path/to/your/ud/corpus\"  # Adjust this path\n",
        "\n",
        "# For this demo, we'll use the test fixtures\n",
        "from pathlib import Path\n",
        "UD_PATH = Path(\"../tests/fixtures/ud\")\n",
        "\n",
        "U = UDReader(root=UD_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fileids-header",
      "metadata": {},
      "source": [
        "## Fileids and format detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "## List available files\n",
        "\n",
        "files = U.fileids()\n",
        "print(f\"Total files: {len(files)}\")\n",
        "pprint(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create readers for specific formats\n",
        "\n",
        "# CONLLU only (full UD with dependencies)\n",
        "U_conllu = UDReader(root=UD_PATH, fileids=\"*.conllu\")\n",
        "print(f\"CONLLU files: {U_conllu.fileids()}\")\n",
        "\n",
        "# CONLLUP only (LASLA format, no dependencies)\n",
        "U_conllup = UDReader(root=UD_PATH, fileids=\"*.conllup\")\n",
        "print(f\"CONLLUP files: {U_conllup.fileids()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect format: CONLLU vs CONLLUP\n",
        "# CONLLU has dependency annotations, CONLLUP does not\n",
        "\n",
        "print(f\"CONLLU has dependencies: {U_conllu.has_dependencies()}\")\n",
        "print(f\"CONLLUP has dependencies: {U_conllup.has_dependencies()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "annotations-header",
      "metadata": {},
      "source": [
        "## Annotation source: File vs LatinCy\n",
        "\n",
        "By default, UDReader uses annotations directly from the CONLLU/CONLLUP file. This preserves the original treebank annotations.\n",
        "\n",
        "Set `use_file_annotations=False` to use LatinCy instead, storing originals in `Token._.ud_*` extensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Default: use_file_annotations=True\n",
        "# Annotations come directly from the UD file\n",
        "\n",
        "print(f\"use_file_annotations: {U.use_file_annotations}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare: file annotations vs LatinCy\n",
        "# (Requires LatinCy model to be installed for the second case)\n",
        "\n",
        "# File annotations (default)\n",
        "doc_file = next(U_conllu.docs())\n",
        "print(\"Using file annotations:\")\n",
        "for token in doc_file[:5]:\n",
        "    print(f\"  {token.text}: lemma={token.lemma_}, pos={token.pos_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "docs-header",
      "metadata": {},
      "source": [
        "## Doc structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a file to work with\n",
        "sample_file = U_conllu.fileids()[0]\n",
        "print(f\"Working with: {sample_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-21",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Docs - spaCy Doc objects with UD annotations\n",
        "\n",
        "doc = next(U_conllu.docs(sample_file))\n",
        "print(f\"Doc text: {doc.text}\")\n",
        "print(f\"Number of tokens: {len(doc)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-22",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Texts - raw strings (zero NLP overhead)\n",
        "\n",
        "text = next(U_conllu.texts(sample_file))\n",
        "print(f\"Raw text: {text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ud-extensions-header",
      "metadata": {},
      "source": [
        "## UD-specific Token extensions\n",
        "\n",
        "UDReader provides access to all CoNLL-U fields via custom extensions:\n",
        "\n",
        "| Extension | Description |\n",
        "|-----------|-------------|\n",
        "| `Token._.ud_id` | Original token ID from file |\n",
        "| `Token._.ud_lemma` | Lemma from UD file |\n",
        "| `Token._.ud_upos` | Universal POS tag |\n",
        "| `Token._.ud_xpos` | Language-specific POS tag |\n",
        "| `Token._.ud_feats` | Morphological features (dict) |\n",
        "| `Token._.ud_head` | Head token index |\n",
        "| `Token._.ud_deprel` | Dependency relation |\n",
        "| `Token._.ud_deps` | Enhanced dependencies |\n",
        "| `Token._.ud_misc` | Miscellaneous field (dict) |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-ext-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access UD extensions on tokens\n",
        "\n",
        "doc = next(U_conllu.docs())\n",
        "\n",
        "print(\"Token details from UD file:\")\n",
        "for token in doc[:5]:\n",
        "    print(f\"\\n{token.text}:\")\n",
        "    print(f\"  ud_id: {token._.ud_id}\")\n",
        "    print(f\"  ud_lemma: {token._.ud_lemma}\")\n",
        "    print(f\"  ud_upos: {token._.ud_upos}\")\n",
        "    print(f\"  ud_xpos: {token._.ud_xpos}\")\n",
        "    print(f\"  ud_feats: {token._.ud_feats}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-ext-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Morphological features are stored as dictionaries\n",
        "\n",
        "doc = next(U_conllu.docs())\n",
        "\n",
        "print(\"Morphological analysis:\")\n",
        "for token in doc:\n",
        "    if token._.ud_feats:  # If token has features\n",
        "        print(f\"\\n{token.text} ({token._.ud_upos}):\")\n",
        "        for feat, value in token._.ud_feats.items():\n",
        "            print(f\"  {feat}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-ext-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dependency information (CONLLU only, not CONLLUP)\n",
        "\n",
        "doc = next(U_conllu.docs())\n",
        "\n",
        "print(\"Dependency structure:\")\n",
        "for token in doc[:8]:\n",
        "    if token._.ud_head is not None:\n",
        "        print(f\"{token._.ud_id} {token.text} --{token._.ud_deprel}--> {token._.ud_head}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-ext-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare CONLLU (with deps) vs CONLLUP (without deps)\n",
        "\n",
        "doc_conllu = next(U_conllu.docs())\n",
        "doc_conllup = next(U_conllup.docs())\n",
        "\n",
        "print(\"CONLLU token (has dependencies):\")\n",
        "t = doc_conllu[0]\n",
        "print(f\"  {t.text}: head={t._.ud_head}, deprel={t._.ud_deprel}\")\n",
        "\n",
        "print(\"\\nCONLLUP token (no dependencies):\")\n",
        "t = doc_conllup[0]\n",
        "print(f\"  {t.text}: head={t._.ud_head}, deprel={t._.ud_deprel}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sentences-header",
      "metadata": {},
      "source": [
        "## Sentences\n",
        "\n",
        "Sentences preserve `sent_id` from the CoNLL-U metadata as citations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-sent-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterate over sentences\n",
        "\n",
        "for sent in U_conllu.sentences():\n",
        "    print(f\"{sent._.citation}: {sent.text}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-sent-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sentences are stored in doc.spans[\"sentences\"]\n",
        "\n",
        "doc = next(U_conllu.docs())\n",
        "\n",
        "print(f\"Number of sentences: {len(doc.spans.get('sentences', []))}\")\n",
        "for sent in doc.spans.get(\"sentences\", []):\n",
        "    print(f\"  {sent._.citation}: {sent.text[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "raw-header",
      "metadata": {},
      "source": [
        "## Raw token access with tokens_with_annotations()\n",
        "\n",
        "For maximum performance when you need all UD fields, use `tokens_with_annotations()` which returns dictionaries instead of spaCy objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-raw-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get tokens as dictionaries with all UD fields\n",
        "\n",
        "from itertools import islice\n",
        "\n",
        "tokens = list(islice(U_conllu.tokens_with_annotations(), 5))\n",
        "\n",
        "print(\"First 5 tokens as dicts:\")\n",
        "for tok in tokens:\n",
        "    pprint(tok)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-raw-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract specific fields across the corpus\n",
        "\n",
        "# Get all unique UPOS tags\n",
        "upos_tags = set(\n",
        "    tok[\"upos\"] for tok in U.tokens_with_annotations()\n",
        "    if tok[\"upos\"]\n",
        ")\n",
        "print(f\"UPOS tags in corpus: {sorted(upos_tags)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-raw-3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count morphological features\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "case_counts = Counter()\n",
        "for tok in U.tokens_with_annotations():\n",
        "    if \"Case\" in tok[\"feats\"]:\n",
        "        case_counts[tok[\"feats\"][\"Case\"]] += 1\n",
        "\n",
        "print(\"Case distribution:\")\n",
        "for case, count in case_counts.most_common():\n",
        "    print(f\"  {case}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tokens-header",
      "metadata": {},
      "source": [
        "## Standard token access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-tok-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokens - spaCy Token objects\n",
        "\n",
        "tokens = list(islice(U_conllu.tokens(), 10))\n",
        "\n",
        "for i, t in enumerate(tokens, 1):\n",
        "    print(f\"Token {i}: {t.text} (lemma: {t.lemma_}, pos: {t.pos_})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-tok-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Token attributes come from the UD file\n",
        "\n",
        "token = next(U_conllu.tokens())\n",
        "\n",
        "print(f\"Standard spaCy attributes (from UD file):\")\n",
        "print(f\"  text: {token.text}\")\n",
        "print(f\"  lemma_: {token.lemma_}\")\n",
        "print(f\"  pos_: {token.pos_}\")\n",
        "print(f\"  tag_: {token.tag_}\")\n",
        "print(f\"  morph: {token.morph}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pos-analysis-header",
      "metadata": {},
      "source": [
        "## POS tag analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-pos-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# POS distribution in the corpus\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "pos_counts = Counter(t.pos_ for t in U.tokens() if t.pos_)\n",
        "\n",
        "print(\"POS tag distribution:\")\n",
        "for pos, count in pos_counts.most_common():\n",
        "    print(f\"  {pos}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-pos-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all nouns with their cases\n",
        "\n",
        "doc = next(U_conllu.docs())\n",
        "\n",
        "print(\"Nouns and their cases:\")\n",
        "for token in doc:\n",
        "    if token.pos_ == \"NOUN\" and token._.ud_feats:\n",
        "        case = token._.ud_feats.get(\"Case\", \"?\")\n",
        "        print(f\"  {token.text} ({token.lemma_}): {case}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "concordance-header",
      "metadata": {},
      "source": [
        "## Concordance and search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-conc-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build a concordance by lemma\n",
        "\n",
        "conc = U.concordance(basis=\"lemma\")\n",
        "\n",
        "print(f\"Unique lemmas: {len(conc)}\")\n",
        "print(\"\\nSample entries:\")\n",
        "for lemma in list(conc.keys())[:5]:\n",
        "    print(f\"  {lemma}: {conc[lemma]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-conc-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# find_sents() works with UDReader too\n",
        "\n",
        "# Search by exact form\n",
        "for hit in U.find_sents(forms=[\"augur\", \"narrare\"]):\n",
        "    print(f\"{hit['citation']}: {hit['sentence']}\")\n",
        "    print(f\"  Matched: {hit['matches']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "metadata-header",
      "metadata": {},
      "source": [
        "## Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-meta-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get metadata for a file\n",
        "\n",
        "doc = next(U.docs())\n",
        "\n",
        "print(f\"File: {doc._.fileid}\")\n",
        "print(f\"Metadata: {doc._.metadata}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-meta-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metadata includes format detection\n",
        "\n",
        "for fileid, meta in U.metadata():\n",
        "    print(f\"{fileid}:\")\n",
        "    print(f\"  format: {meta.get('format', 'unknown')}\")\n",
        "    print(f\"  n_sentences: {meta.get('n_sentences', '?')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caching-header",
      "metadata": {},
      "source": [
        "## Caching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-cache",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Documents are cached by default\n",
        "\n",
        "# First access - cache miss\n",
        "doc1 = next(U.docs())\n",
        "print(f\"After first access: {U.cache_stats()}\")\n",
        "\n",
        "# Second access - cache hit\n",
        "doc2 = next(U.docs())\n",
        "print(f\"After second access: {U.cache_stats()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-cache-2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Disable caching for memory-constrained environments\n",
        "\n",
        "U_nocache = UDReader(root=UD_PATH, cache=False)\n",
        "print(f\"Caching enabled: {U_nocache.cache_enabled}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "comparison-header",
      "metadata": {},
      "source": [
        "## CONLLU vs CONLLUP format comparison\n",
        "\n",
        "| Feature | CONLLU | CONLLUP (LASLA) |\n",
        "|---------|--------|------------------|\n",
        "| File extension | `.conllu` | `.conllup` |\n",
        "| Dependency annotations | Yes | No |\n",
        "| `Token._.ud_head` | Populated | `None` |\n",
        "| `Token._.ud_deprel` | Populated | `None` |\n",
        "| Lemma, POS, Morph | Yes | Yes |\n",
        "| `has_dependencies()` | `True` | `False` |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "summary-header",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The `UDReader` is ideal when:\n",
        "\n",
        "- You have pre-annotated corpora in CoNLL-U or CONLLUP format\n",
        "- You want to preserve original treebank annotations\n",
        "- You need access to full morphological analysis\n",
        "- You're working with LASLA or other CONLLUP data\n",
        "\n",
        "Use `use_file_annotations=False` when you want to compare treebank annotations with LatinCy's predictions."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
